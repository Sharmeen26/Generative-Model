# Step 1: Load Data
from Bio import SeqIO


# Function to load data from a FASTA file
def load_fasta_file(file_path):
    sequences = []
    virus_types = []
    for record in SeqIO.parse(file_path, "fasta"):
        sequences.append(str(record.seq))
        virus_type = record.description.split()[
            0
        ]  # Assuming virus type is the first element
        virus_types.append(virus_type)
    return sequences, virus_types


# Path to your FASTA file
fasta_file_path = "file path"
# Load data from the FASTA file
sequences, virus_types = load_fasta_file(fasta_file_path)

# Print the number of sequences and types
num_sequences = len(sequences)
print("Number of Sequences:", num_sequences)

# Check the first few sequences and their associated virus types
for i in range(5):  # Adjust the range to see more sequences if needed
    print(f"Sequence {i+1}: {sequences[i]}")
    print(f"Virus Type: {virus_types[i]}")
    print("------")

# Step 2 Prepare Data For Model
import numpy as np
from tensorflow.keras.preprocessing.text import Tokenizer
from tensorflow.keras.preprocessing.sequence import pad_sequences


def prepare_data(sequences):
    all_sequences = sequences
    tokenizer = Tokenizer(char_level=True)
    tokenizer.fit_on_texts(all_sequences)

    total_words = len(tokenizer.word_index) + 1

    input_sequences = []
    for seq in all_sequences:
        token_list = tokenizer.texts_to_sequences([seq])[0]
        for i in range(1, len(token_list)):
            n_gram_sequence = token_list[: i + 1]
            input_sequences.append(n_gram_sequence)

    max_sequence_length = max([len(seq) for seq in input_sequences])
    padded_sequences = pad_sequences(
        input_sequences, maxlen=max_sequence_length, padding="pre"
    )

    predictors, label = padded_sequences[:, :-1], padded_sequences[:, -1]

    return predictors, label, total_words, max_sequence_length, tokenizer
    # Prepare data
predictors, label, total_words, max_sequence_length, tokenizer = prepare_data(sequences)

# Check the prepared data
print(predictors.shape)
print(label.shape)
print(total_words)
print(max_sequence_length)

# Step 3
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv1D, Flatten, Dropout, Embedding, UpSampling1D, Reshape
from tensorflow.keras.optimizers import Adam

# Define parameters
sequence_length = 300  # Adjust based on your gene sequence length
vocab_size = 4  # A, C, G, T (DNA nucleotide bases)
embedding_dim = 50  # Size of embedding space
conv_filters = 64  # Number of convolutional filters
kernel_size = 5  # Kernel size for the convolution
dropout_rate = 0.2  # Dropout rate to prevent overfitting
learning_rate = 0.001  # Learning rate for the optimizer

# Generator model
def create_generator():
    model = Sequential()

    # Embedding layer
    model.add(Embedding(input_dim=vocab_size, output_dim=embedding_dim, input_length=sequence_length))

    # 1D Convolutional layers
    model.add(Conv1D(filters=conv_filters, kernel_size=kernel_size, activation='relu', input_shape=(sequence_length, embedding_dim)))
    model.add(UpSampling1D(size=2))
    model.add(Dropout(dropout_rate))

    model.add(Conv1D(filters=conv_filters, kernel_size=kernel_size, activation='relu'))
    model.add(UpSampling1D(size=2))
    model.add(Dropout(dropout_rate))

    model.add(Flatten())

    # Output layer
    model.add(Dense(sequence_length * vocab_size, activation='softmax'))  # Generating one-hot encoded sequence output
    model.add(Reshape((sequence_length, vocab_size)))

    return model

# Create generator model
generator = create_generator()

# Compile the model
generator.compile(optimizer=Adam(learning_rate=learning_rate), loss='categorical_crossentropy')

# Print model summary
generator.build((None, sequence_length))  # Add this line to explicitly build the model with input shape
generator.summary()

# Example of input data: Randomly initialized, replace with real gene sequence data
X_train = np.random.randint(0, vocab_size, (1000, sequence_length))  # Dummy input data
y_train = np.random.randint(0, vocab_size, (1000, sequence_length, vocab_size))  # Dummy output data

# Train the model
generator.fit(X_train, y_train, epochs=30, batch_size=32)

# Step 4: Generating New Sequence Type
import numpy as np
from keras.preprocessing.sequence import pad_sequences


def generate_sequence(model, tokenizer, max_sequence_length, seed_text, next_words):
    for _ in range(next_words):
        token_list = tokenizer.texts_to_sequences([seed_text])[0]
        token_list = pad_sequences(
            [token_list], maxlen=max_sequence_length - 1, padding="pre"
        )
        predicted_probs = model.predict(token_list, verbose=0)[0]

        # Choose the word with some randomness to introduce diversity
        predicted_index = np.random.choice(len(predicted_probs), p=predicted_probs)
        output_word = ""
        for word, index in tokenizer.word_index.items():
            if index == predicted_index:
                output_word = word
                break

        seed_text += output_word.upper()

    return seed_text


def get_user_input():
    while True:
        generate_sequence_input = input(
            "Do you want to generate a sequence? (yes/no): "
            ).lower()
        if generate_sequence_input == "yes":
            length_input = int(
                input(
                    "Enter the length of the sequence to generate (between 100 and 15000): "
                )
            )
            if 100 <= length_input <= 15000:
                num_sequences_input = int(
                    input(
                        "Enter the number of sequences to generate (between 1 and 10): "
                    )
                )
                if 1 <= num_sequences_input <= 10:
                    return True, length_input, num_sequences_input
                else:
                    print(
                        "Please enter a number between 1 and 10 for the number of sequences."
                    )
            else:
                print("Please enter a number between 100 and 15000.")
        elif generate_sequence_input == "no":
            return False, 0, 0
        else:
            print("Invalid input. Please enter 'yes' or 'no'.")
while True:
    generate, length, num_sequences = get_user_input()
    if not generate:
        break

    seed_sequence = "HCV E2:"  # You can change this to start with any type you want
    for _ in range(num_sequences):
        generated_sequence = generate_sequence(
            model, tokenizer, max_sequence_length, seed_sequence, length
        )

        # Print the generated sequence
        print(generated_sequence)
